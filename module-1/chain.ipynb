{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbf2458",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/chain.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238466-lesson-4-chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Chain\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a simple graph with nodes, normal edges, and conditional edges.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 concepts.\n",
    "\n",
    "* Using [chat messages](https://docs.langchain.com/oss/python/langchain/messages) as our graph state\n",
    "* Using [chat models](https://docs.langchain.com/oss/python/integrations/chat) in graph nodes\n",
    "* [Binding tools](https://docs.langchain.com/oss/python/langchain/models#tool-calling) to our chat model\n",
    "* [Executing tool calls](https://docs.langchain.com/oss/python/langchain/models#tool-execution-loop) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Messages\n",
    "\n",
    "Chat models can use [messages](https://docs.langchain.com/oss/python/langchain/messages), which capture different roles within a conversation. \n",
    "\n",
    "LangChain supports various message types, including `HumanMessage`, `AIMessage`, `SystemMessage`, and `ToolMessage`. \n",
    "\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call. \n",
    "\n",
    "Let's create a list of messages. \n",
    "\n",
    "Each message can be supplied with a few things:\n",
    "\n",
    "* `content` - content of the message\n",
    "* `name` - optionally, a message author \n",
    "* `response_metadata` - optionally, a dict of metadata (e.g., often populated by model provider for `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Chat Models\n",
    "\n",
    "Chat models use a sequence of messages as input and support message types, as discussed above.\n",
    "\n",
    "There are [many](https://docs.langchain.com/oss/python/integrations/chat) to choose from! Let's work with OpenAI. \n",
    "\n",
    "Let's check that your `OPENAI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c849b426-3608-4097-bb78-9c7dba936174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
      "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from langchain-google-genai) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from langchain-google-genai) (2.12.4)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai)\n",
      "  Downloading google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai)\n",
      "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.76.0)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (6.33.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.32.5)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai)\n",
      "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai)\n",
      "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from grpcio<2.0.0,>=1.33.2->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.15.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.4.42)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\pmls\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (23.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.5.0)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\pmls\\miniconda3\\envs\\lc-academy-env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.3.0)\n",
      "Downloading langchain_google_genai-3.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.4 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 0.8/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 1.6 MB/s  0:00:01\n",
      "Downloading google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
      "Downloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading grpcio_status-1.76.0-py3-none-any.whl (14 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Installing collected packages: filetype, pyasn1, proto-plus, cachetools, rsa, pyasn1-modules, grpcio-status, google-auth, google-api-core, google-ai-generativelanguage, langchain-google-genai\n",
      "\n",
      "   --- ------------------------------------  1/11 [pyasn1]\n",
      "   --- ------------------------------------  1/11 [pyasn1]\n",
      "   --- ------------------------------------  1/11 [pyasn1]\n",
      "   ------- --------------------------------  2/11 [proto-plus]\n",
      "   ------- --------------------------------  2/11 [proto-plus]\n",
      "   -------------- -------------------------  4/11 [rsa]\n",
      "   -------------- -------------------------  4/11 [rsa]\n",
      "   ------------------ ---------------------  5/11 [pyasn1-modules]\n",
      "   ------------------ ---------------------  5/11 [pyasn1-modules]\n",
      "   ------------------ ---------------------  5/11 [pyasn1-modules]\n",
      "   ------------------ ---------------------  5/11 [pyasn1-modules]\n",
      "   ------------------ ---------------------  5/11 [pyasn1-modules]\n",
      "   ------------------ ---------------------  5/11 [pyasn1-modules]\n",
      "   ------------------ ---------------------  5/11 [pyasn1-modules]\n",
      "   ------------------------- --------------  7/11 [google-auth]\n",
      "   ------------------------- --------------  7/11 [google-auth]\n",
      "   ------------------------- --------------  7/11 [google-auth]\n",
      "   ------------------------- --------------  7/11 [google-auth]\n",
      "   ----------------------------- ----------  8/11 [google-api-core]\n",
      "   ----------------------------- ----------  8/11 [google-api-core]\n",
      "   ----------------------------- ----------  8/11 [google-api-core]\n",
      "   ----------------------------- ----------  8/11 [google-api-core]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------- -------  9/11 [google-ai-generativelanguage]\n",
      "   ------------------------------------ --- 10/11 [langchain-google-genai]\n",
      "   ---------------------------------------- 11/11 [langchain-google-genai]\n",
      "\n",
      "Successfully installed cachetools-6.2.2 filetype-1.2.0 google-ai-generativelanguage-0.9.0 google-api-core-2.28.1 google-auth-2.43.0 grpcio-status-1.76.0 langchain-google-genai-3.2.0 proto-plus-1.26.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2652d5ec-7602-4220-bc6e-b90783ab287b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": [
    "We can load a chat model and invoke it with out list of messages.\n",
    "\n",
    "We can see that the result is an `AIMessage` with specific `response_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)\"\"\"\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "\n",
    ")\n",
    "result = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='That\\'s a fantastic goal! Orcas are incredible creatures. When it comes to the \"best\" place to see them in the US, it really comes down to two primary regions, each offering a slightly different experience:\\n\\n1.  **The San Juan Islands, Washington State (Pacific Northwest)**\\n2.  **Alaska (particularly Southeast Alaska and the Kenai Fjords)**\\n\\nLet\\'s break them down:\\n\\n---\\n\\n### 1. San Juan Islands, Washington State\\n\\n**Why it\\'s often considered the #1 spot:**\\n\\n*   **Reliability (for Bigg\\'s Orcas):** While the critically endangered Southern Resident Killer Whales (SRKW) that historically frequented these waters are now less predictable due to declining salmon runs, the San Juan Islands have become an *excellent* place to see **Bigg\\'s (Transient) Killer Whales**. These marine mammal-eating orcas are thriving and are seen very regularly throughout the spring, summer, and fall.\\n*   **Accessibility:** Relatively easy to get to from Seattle. You can take a ferry or a small plane to islands like San Juan Island (Friday Harbor), Orcas Island, or Lopez Island, which are hubs for whale watching tours.\\n*   **Dedicated Whale Watching Industry:** There\\'s a mature and highly regulated whale watching industry here, with many experienced operators committed to ethical viewing practices (following \"Be Whale Wise\" guidelines).\\n*   **Scenery:** The islands themselves are beautiful, offering a picturesque backdrop of evergreen forests, rocky shorelines, and calm waters.\\n*   **Other Wildlife:** You\\'ll often see other marine mammals like humpback whales, minke whales, harbor seals, sea lions, and various seabirds.\\n\\n**Best Time to Visit:**\\n*   **Late Spring through Early Fall (May to September/October)** is generally the peak season for whale watching. July and August offer the warmest weather and longest daylight hours.\\n\\n**Tips:**\\n*   **Book a reputable tour:** Choose a company that prioritizes the whales\\' well-being and follows all regulations.\\n*   **Stay on San Juan Island:** Friday Harbor is a popular base with many tour departures.\\n*   **Be patient:** While sightings are frequent, they are wild animals, and there are no guarantees.\\n\\n---\\n\\n### 2. Alaska\\n\\n**Why it\\'s a strong contender:**\\n\\n*   **Abundant Bigg\\'s Orcas:** Alaska\\'s rich waters, teeming with seals, sea lions, and other marine mammals, make it a fantastic place to see Bigg\\'s (Transient) Killer Whales.\\n*   **Stunning Scenery:** Whale watching in Alaska often comes with the added bonus of breathtaking landscapes – glaciers, towering mountains, and pristine fjords.\\n*   **Diverse Wildlife:** You\\'ll almost certainly see humpback whales, sea otters, puffins, eagles, and possibly even bears on shore.\\n*   **Specific Hotspots:**\\n    *   **Kenai Fjords National Park (Seward):** Many tours depart from Seward and explore the fjords, which are rich in marine life.\\n    *   **Prince William Sound (Whittier/Valdez):** Another excellent area for marine mammal viewing.\\n    *   **Southeast Alaska (Juneau, Sitka):** Whale watching tours from these cities often encounter orcas, especially during the salmon runs.\\n\\n**Best Time to Visit:**\\n*   **Summer (June, July, August)** is the prime season for whale watching in Alaska, coinciding with the best weather and longest daylight hours.\\n\\n**Tips:**\\n*   **Combine with other activities:** Whale watching is often part of a larger Alaskan adventure, such as a cruise or a land-based tour exploring national parks.\\n*   **Dress in layers:** Alaskan weather can be unpredictable, even in summer.\\n\\n---\\n\\n### Other US Locations (Less Reliable for Orcas)\\n\\n*   **Monterey Bay, California:** While Orcas *do* pass through Monterey Bay, especially during gray whale migration or when hunting other marine mammals, sightings are less consistent than in the PNW or Alaska. It\\'s more opportunistic.\\n*   **Hawaii:** You might hear about \"killer whales\" in Hawaii, but these are typically **False Killer Whales**, which are a different species, though also fascinating. True Orcas are very rare in Hawaiian waters.\\n\\n---\\n\\n**In summary:**\\n\\n*   For the **most reliable and accessible dedicated orca watching experience focused on Bigg\\'s Killer Whales**, the **San Juan Islands, Washington**, are likely your best bet.\\n*   For an incredible wildlife experience that includes **frequent Bigg\\'s Orca sightings amidst spectacular wilderness**, **Alaska** is an unparalleled choice.\\n\\nNo matter where you go, remember that these are wild animals, and every sighting is a privilege! Enjoy your research and potential trip!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--2394cc0d-2399-4c11-b32b-bec68bba232f-0', usage_metadata={'input_tokens': 46, 'output_tokens': 2170, 'total_tokens': 2216, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1156}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_feedback': {'block_reason': 0, 'safety_ratings': []},\n",
       " 'finish_reason': 'STOP',\n",
       " 'model_name': 'gemini-2.5-flash',\n",
       " 'safety_ratings': [],\n",
       " 'model_provider': 'google_genai'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Tools\n",
    "\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language. \n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user. \n",
    "\n",
    "And, it will return an output that adheres to the tool's schema. \n",
    "\n",
    "[Many LLM providers support tool calling](https://docs.langchain.com/oss/python/integrations/chat) and [tool calling interface](https://blog.langchain.com/improving-core-tool-interfaces-and-docs-in-langchain/) in LangChain is simple. \n",
    " \n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's showcase a simple example of tool calling!\n",
    " \n",
    "The `multiply` function is our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., `\"What is 2 multiplied by 3\"` - we see a tool call returned. \n",
    "\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"what is 2 multiplied by 3\", name=\"Lance\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': '3537d773-d467-47b3-85c9-ef569e468064',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Using messages as state\n",
    "\n",
    "With these foundations in place, we can now use  [messages](https://docs.langchain.com/oss/python/langchain/overview#messages) in our graph state.\n",
    "\n",
    "Let's define our state, `MessagesState`, as a `TypedDict` with a single key: `messages`.\n",
    "\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Reducers\n",
    "\n",
    "Now, we have a minor problem! \n",
    "\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "\n",
    "But, this new value will overwrite the prior `messages` value!\n",
    " \n",
    "As our graph runs, we want to **append** messages to our `messages` state key.\n",
    " \n",
    "We can use [reducer functions](https://docs.langchain.com/oss/python/langgraph/graph-api#reducers) to address this.\n",
    "\n",
    "Reducers specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should *override it* as we saw before.\n",
    " \n",
    "But, to append messages, we can use the pre-built `add_messages` reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We simply need to annotate our `messages` key with the `add_messages` reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Since having a list of messages in graph state is so common, LangGraph has a pre-built  [`MessagesState`](https://docs.langchain.com/oss/python/langgraph/graph-api#messagesstate)! \n",
    "\n",
    "`MessagesState` is defined: \n",
    "\n",
    "* With a pre-build single `messages` key\n",
    "* This is a list of `AnyMessage` objects \n",
    "* It uses the `add_messages` reducer\n",
    "\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypedDict`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='9e3a0bfe-18bf-4b1f-a75e-80f6e4dee5dd'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='fc0f5caf-f4b9-4e72-bbcd-e40bc218d0fa'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='fb427798-e279-4efb-bc6b-2a150c07c623')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)\"\"\"\n",
    "\n",
    "initial_messages = [AIMessage(content = \"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                     HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                    ]\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "add_messages(initial_messages, new_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\"\"\"\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "def tool_calling_llm(state:MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": [
    "If we pass in `Hello!`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I am a large language model, able to perform various tasks. What can I do for you today?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": [
    "The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, this shoaib ahmad learning langchain/langgraph to became and ai engineer\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': \"That's great, Shoaib Ahmad! LangChain and LangGraph are excellent choices for becoming an AI engineer. They'll definitely help you build powerful applications.\\n\\nWhat kind of AI applications are you hoping to build? Or perhaps you have some questions about LangChain/LangGraph? I'm here to help!\", 'extras': {'signature': 'CuQBAXLI2nxY2hQy9oAhiFuuINwz5JlVBjxv/tzWqWIh0ARkyAOPB8S2Fln9uTQalZm2aR0ZK8viHnFQMShcBFqI4yo129MSdLVtOcFnovV1LqvuiqyIFLtniwSVXfvtVgUtUpg8ouRFCiVgCS7Q5DNsO8so8R1G96pJ5DzmiH/BO7Fw4hNQm9YSu2V9A5OBfihAH5KwM0jGSLMcK8EBkjhmjFMmWBJpfcvAhiQre+obnsTUIxHCk8A6SNX6VUKaDrnLmdK3CwFdsDL4I+W8jCttHKIK0KydmiCQNA8w5N8hJI1hYgBl'}}]\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello, this shoaib ahmad learning langchain/langgraph to became and ai engineer\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fbae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
